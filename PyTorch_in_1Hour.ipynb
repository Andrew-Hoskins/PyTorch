{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "wu6-A4peFoom",
        "5xqZa3tVFuhx",
        "reSxbOQpHGL4",
        "BOFsBKrIJ_0d"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNlWXtX0LJxWfB+vS3FcTHL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andrew-Hoskins/PyTorch/blob/main/PyTorch_in_1Hour.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch in One Hour: From Tensors to Training Neural Networks on Multiple GPUs\n",
        "\n",
        "* Designed to cover the essential topics of the deep leanring libray PyTorch.\n",
        "* Link to course by Sebastian Raschka: https://sebastianraschka.com/teaching/pytorch-1h/\n"
      ],
      "metadata": {
        "id": "qSapOq-sz2IH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Components of PyTorch\n",
        "\n",
        "PyTorch is developed by Facebook’s AI Research lab (FAIR, now called Meta AI).\n",
        "\n",
        "* A tensor library that extends the concept of array oriented programming library Numpy.\n",
        "*  PyTorch is an automatic differentiation engine, also known as autograd, which enables the automatic computation of gradients.\n",
        "* PyTorch is a deep learning library, meaning that it offers modular, flexible, and efficient building blocks."
      ],
      "metadata": {
        "id": "V8Flda4R0xqJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scalars, vectors, matrices, and tensors"
      ],
      "metadata": {
        "id": "wu6-A4peFoom"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7ppUgj5jD-xd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# create a 0D tensor (Scalar)\n",
        "tensor0d = torch.tensor(1)\n",
        "\n",
        "# create a 1D tensor (vector)\n",
        "tendor1d = torch.tensor([1, 2, 3])\n",
        "\n",
        "# create a 2D tensor (matrix)\n",
        "tensor2d = torch.tensor([[1, 2],[3, 4]])\n",
        "\n",
        "# create a 3d tensor\n",
        "tensor3d = torch.tensor([\n",
        "    [1, 2],\n",
        "    [3, 4],\n",
        "    [5, 6],\n",
        "    [7, 8]\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "yTyz3Jr81uGa",
        "outputId": "b7e5f1f9-f421-4653-ae55-1c3b0a7a5d1e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.0+cu126'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor data types"
      ],
      "metadata": {
        "id": "5xqZa3tVFuhx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pytorch adopts the default 64-bit integer, which we can access with `.dtype`\n",
        "tensor1d = torch.tensor([1, 2, 3])\n",
        "print(tensor1d.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUIrxVrsE8JJ",
        "outputId": "69c0b8da-0960-4017-fce1-87687bbfe8dc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can create tensors from floats, with a 32-bit precision by default\n",
        "floatvec = torch.tensor([1.0, 2.0, 3.0])\n",
        "print(floatvec.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yz6It9p1F8GQ",
        "outputId": "1ef3e357-d8ec-43f3-e2b2-a4f84f369568"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can change a dtype with the `.to` method\n",
        "floatvec = tensor1d.to(torch.float32)\n",
        "print(floatvec.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3ABIOsdGkrd",
        "outputId": "144126c5-9f7d-40c9-c403-1e3b35ff4643"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Common PyTorch tensor operations"
      ],
      "metadata": {
        "id": "reSxbOQpHGL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor2d = torch.tensor([\n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6]\n",
        "])\n",
        "print(tensor2d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdCaiTGUHATH",
        "outputId": "5494c094-1426-41d6-9972-ee1776bedf3c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# .shape attribute allows to acces the shape of a tensor\n",
        "print(tensor2d.shape)\n",
        "# this return [2,3] tensor has 2 rows & 3 columns."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQ17Z9A1HVOZ",
        "outputId": "05b58a4d-6117-4e8a-8407-75642970e1af"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can use .reshape to reshape a tensor\n",
        "tensor2d.reshape(3, 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PbY8reRHcJA",
        "outputId": "81d69aea-5ea2-4dbc-858c-d5f002e1227e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4],\n",
              "        [5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can use .T to transpose a tensor, flipping it across its diagnol\n",
        "tensor2d.T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIvyw-aZH8z1",
        "outputId": "9e70801e-81fd-4605-ff26-9534303f4111"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 4],\n",
              "        [2, 5],\n",
              "        [3, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# multiply two matrices use the .matmul method\n",
        "tensor2d.matmul(tensor2d.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VWoEejEIa6C",
        "outputId": "444fd29e-aea9-4053-cfcb-f30a7d2ea3c1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[14, 32],\n",
              "        [32, 77]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# or use the @ operator\n",
        "tensor2d @ tensor2d.T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yq7El2iHJS0y",
        "outputId": "8ee44554-ef2e-435d-aeba-7528b9213b5b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[14, 32],\n",
              "        [32, 77]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seeing models as computation graphs"
      ],
      "metadata": {
        "id": "BOFsBKrIJ_0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "# The forward pass of a logistic regression classifier (single layer neural network).\n",
        "# returning a score between 0 and 1 that is compared to the true label (0 or 1) when computing the loss\n",
        "\n",
        "y = torch.tensor([1.0])  # True Label\n",
        "x1 = torch.tensor([1.1]) # Input Feature\n",
        "w1 = torch.tensor([2.2]) # Weight parameter\n",
        "b = torch.tensor([0.0])  # Bias unit\n",
        "\n",
        "z = x1 * w1 * b          # net input\n",
        "a = torch.sigmoid(z)     # activation and output\n",
        "\n",
        "loss = F.binary_cross_entropy(a, y)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXV8zdwEJfr3",
        "outputId": "fd72a327-4385-4655-b582-48cd4b057fce"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.6931)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Automatic Differentiation (Autograd)**\n",
        "By tracking every operation performed on a tensor, PyTorchs autograd engine constructs a computational graph in the background. Then calling the grad function, we can compute the gradient of the loss with respects to model parameter w1."
      ],
      "metadata": {
        "id": "B5vtHPTU6tmg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.autograd import grad\n",
        "\n",
        "y = torch.tensor([1.0])\n",
        "x1 = torch.tensor([1.1])\n",
        "w1 = torch.tensor([2.2], requires_grad=True)\n",
        "b = torch.tensor([0.0], requires_grad=True)\n",
        "\n",
        "z = x1 * w1 * b\n",
        "a = torch.sigmoid(z)\n",
        "\n",
        "loss = F.binary_cross_entropy(a, y)\n",
        "\n",
        "grad_L_w1 = grad(loss, w1, retain_graph=True) # Graph is usually destroyed after calculating the gradient to save memory, so we set retain_graph.\n",
        "grad_L_b = grad(loss, b, retain_graph=True)\n",
        "\n",
        "print(grad_L_w1)\n",
        "print(grad_L_b)\n"
      ],
      "metadata": {
        "id": "tehi455cLC6L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89c86291-b65e-4c59-b97c-243e7e466347"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([-0.]),)\n",
            "(tensor([-1.2100]),)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can call '.backward()' on the loss, and PyTorch will compute the gradients of all leaf nodes on the graph.\n",
        "loss.backward()\n",
        "print(w1.grad)\n",
        "print(b.grad)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiDHCCIU8MiN",
        "outputId": "aecedefd-a963-4e11-e275-72b966748138"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.])\n",
            "tensor([-1.2100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multilayer Neural Network\n",
        "\n",
        "The following code implemets a classic multilayer perceptron with two hidden layers, to illustrate typical ussage of the Module class."
      ],
      "metadata": {
        "id": "bD9Cw9tM816N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(torch.nn.Module):\n",
        "    def __init__(self, num_inputs, num_outputs):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers = torch.nn.Sequential(\n",
        "\n",
        "            # 1st hidden layer\n",
        "            torch.nn.Linear(num_inputs, 30),\n",
        "            torch.nn.ReLU(),\n",
        "\n",
        "            # 2nd hidden layer\n",
        "            torch.nn.Linear(30, 20),\n",
        "            torch.nn.ReLU(),\n",
        "\n",
        "            # Output layer\n",
        "            torch.nn.Linear(20, num_outputs),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = self.layers(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "-EK5_9XP8soX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork(50, 3)"
      ],
      "metadata": {
        "id": "g4L3aNWV-ie7"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIY0_eHJ-j1P",
        "outputId": "34130409-02d2-41a0-a67c-1a3f895b4868"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=30, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=30, out_features=20, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=20, out_features=3, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that each parameters for which requiers_grad=True counts as a trainable parameter and will be updated during training."
      ],
      "metadata": {
        "id": "r2ZsPoLi_iBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the number of parameters\n",
        "num_params = sum(\n",
        "    p.numel() for p in model.parameters() if p.requires_grad\n",
        ")\n",
        "print(\"Total number of trainable parameters:\", num_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzIEBpCa-v8w",
        "outputId": "66973031-6150-402c-d5b7-bb400a466048"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of trainable parameters: 2213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the weight parameter matrix at position 0\n",
        "print(model.layers[0].weight)\n",
        "print(model.layers[0].weight.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWZmXwHe_RZE",
        "outputId": "f4d7a0d6-3aa6-4947-bea2-ab64f98f89c1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.0566, -0.1247,  0.0923,  ..., -0.1358, -0.1182,  0.0231],\n",
            "        [-0.0944, -0.1309, -0.0618,  ..., -0.0339,  0.0519,  0.0194],\n",
            "        [-0.1262,  0.0668, -0.1083,  ..., -0.0490, -0.1103,  0.0055],\n",
            "        ...,\n",
            "        [-0.0413,  0.1109,  0.0854,  ...,  0.0804, -0.0243,  0.0683],\n",
            "        [-0.0818,  0.0963, -0.0376,  ...,  0.0278,  0.1105, -0.0058],\n",
            "        [-0.0203, -0.1131,  0.0039,  ..., -0.1350,  0.0813,  0.0782]],\n",
            "       requires_grad=True)\n",
            "torch.Size([30, 50])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets now see how its used via the forward pass."
      ],
      "metadata": {
        "id": "1YyEjreAAXnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "X = torch.rand((1, 50))\n",
        "out = model(X)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwSWPHVb_zCV",
        "outputId": "5ecdbed1-144d-4b86-99a2-f35f093ca632"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0019,  0.0778, -0.1952]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, grad_fn=<AddmmBackward0> represents the last-used function to compute a variable in the computational graph. Means that the tensor we are inspecting was created via a matrix multiplication and addition operation. PyTorch will use this information when it computes gradients during backpropagation.\n",
        "\n",
        "If we just want to use a network without training or backpropagation, for example, if we use it for prediction after training, constructing this computational graph for backpropagation can be wasteful as it performs unnecessary computations and consumes additional memory."
      ],
      "metadata": {
        "id": "P4HDGji4BBpj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    out = model(X)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVzPz2C6AnA0",
        "outputId": "6e3b34c6-4b54-4c03-b942-70d6adf5a3bd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0019,  0.0778, -0.1952]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In PyTorch, it’s common practice to code models such that they return the outputs of the last layer (logits) without passing them to a nonlinear activation function.\n",
        "That’s because PyTorch’s commonly used loss functions combine the softmax.\n",
        "\n",
        "we have to call the softmax function explicitly.\n",
        "The values can now be interpreted as class-membership probabilities that sum up to 1."
      ],
      "metadata": {
        "id": "4ZF0MVFXB-Rx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    out = torch.softmax(model(X), dim=1)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaaLd7EmBjHM",
        "outputId": "a435c8e0-240d-4ee7-b18c-c7d2eee5de1a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3440, 0.3725, 0.2835]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loaders\n",
        "\n",
        "Lets start by creating a simple toy dataset of five training examples with two features, we will also create a tensor containing the corresponding class labels"
      ],
      "metadata": {
        "id": "hiw99MoHCehd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = torch.tensor([\n",
        "    [-1.2, 3.1],\n",
        "    [-0.9, 2.9],\n",
        "    [-0.5, 2.6],\n",
        "    [2.3, -1.1],\n",
        "    [2.7, -1.5]\n",
        "])\n",
        "\n",
        "Y_train = torch.tensor([0, 0, 0, 1, 1])"
      ],
      "metadata": {
        "id": "y0OuH8YQCi59"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = torch.tensor([\n",
        "    [-0.8, 2.8],\n",
        "    [2.6, -1.6]\n",
        "])\n",
        "\n",
        "Y_test = torch.tensor([0, 1])"
      ],
      "metadata": {
        "id": "TO-HCK1lwWbI"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we create a custom dataset class, by subclassing from PyTorch’s Dataset parent class."
      ],
      "metadata": {
        "id": "7utaUyl7xO1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class ToyDataset(Dataset):\n",
        "    def __init__(self, X, Y):\n",
        "         self.features = X\n",
        "         self.labels = Y\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        one_x = self.features[index]\n",
        "        one_y = self.labels[index]\n",
        "        return one_x, one_y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.labels.shape[0]\n",
        "\n",
        "train_ds = ToyDataset(X_train, Y_train)\n",
        "test_ds = ToyDataset(X_test, Y_test)"
      ],
      "metadata": {
        "id": "CjXd-5sXxJEJ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we defined a PyTorch Dataset class, we can use PyTorch's DataLoader class to sample from it."
      ],
      "metadata": {
        "id": "TSVUGjDky-4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset = train_ds,\n",
        "    batch_size=2,\n",
        "    shuffle=True,\n",
        "    num_workers = 0,\n",
        "    drop_last=True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_ds,\n",
        "    batch_size=2,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")"
      ],
      "metadata": {
        "id": "vGP1fvZryeBk"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have five training examples thats no evenly divisable by 2.\n",
        "So its recommended to drop the last batch in this example as the 3rd batch will only contain one example."
      ],
      "metadata": {
        "id": "aLaBp6JT0eHP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, (X, Y) in enumerate(train_loader):\n",
        "    print(f\"Batch {idx+1}:\", X, Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6klE2WrXyyF-",
        "outputId": "e4941d7a-1140-461a-bb86-c44019c32cea"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1: tensor([[ 2.3000, -1.1000],\n",
            "        [-0.9000,  2.9000]]) tensor([1, 0])\n",
            "Batch 2: tensor([[-1.2000,  3.1000],\n",
            "        [-0.5000,  2.6000]]) tensor([0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Loop"
      ],
      "metadata": {
        "id": "czRxjaRb1ThD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = NeuralNetwork(num_inputs=2, num_outputs=2)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.5) # stochastic gradient descent\n",
        "\n",
        "num_epochs = 3\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    model.train()\n",
        "    for batch_idx, (features, labels) in enumerate(train_loader):\n",
        "\n",
        "        logits = model(features)\n",
        "\n",
        "        loss = F.cross_entropy(logits, labels) # Loss Funtion which will apply the softmax\n",
        "\n",
        "        optimizer.zero_grad() # zero the gradient so they don't accumulate\n",
        "        loss.backward()\n",
        "        optimizer.step() # use the gradients to update the model parameters to minimize the loss\n",
        "\n",
        "        ### Logging\n",
        "        print(f\"Epoch: {epoch+1:03d}/{num_epochs:03d}\"\n",
        "              f\" | Batch {batch_idx:03d}/{len(train_loader):03d}\"\n",
        "              f\" | Train/Val Loss {loss:.2f}\")\n",
        "\n",
        "    model.eval()"
      ],
      "metadata": {
        "id": "R2CF1M3y1Lo7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf72dda6-46e4-49f1-c1b5-9c07885d3fed"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001/003 | Batch 000/002 | Train/Val Loss 0.75\n",
            "Epoch: 001/003 | Batch 001/002 | Train/Val Loss 0.65\n",
            "Epoch: 002/003 | Batch 000/002 | Train/Val Loss 0.44\n",
            "Epoch: 002/003 | Batch 001/002 | Train/Val Loss 0.13\n",
            "Epoch: 003/003 | Batch 000/002 | Train/Val Loss 0.03\n",
            "Epoch: 003/003 | Batch 001/002 | Train/Val Loss 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the models outputs as raw logits\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_train)\n",
        "print(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmTI-kybEtI1",
        "outputId": "79454f8d-72c0-4582-d25a-c4af287a9954"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 2.8569, -4.1618],\n",
            "        [ 2.5382, -3.7548],\n",
            "        [ 2.0944, -3.1820],\n",
            "        [-1.4814,  1.4816],\n",
            "        [-1.7176,  1.7342]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use PyTorch's softmax function to turn them into probabilites\n",
        "# torch.set_printoptions(sci_mode=False)\n",
        "probas = torch.softmax(outputs, dim=1)\n",
        "print(probas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3T-WXNQFz8g",
        "outputId": "a4305b92-67d2-489d-c1ce-afaa615bc619"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[9.9911e-01, 8.9419e-04],\n",
            "        [9.9815e-01, 1.8458e-03],\n",
            "        [9.9491e-01, 5.0852e-03],\n",
            "        [4.9127e-02, 9.5087e-01],\n",
            "        [3.0714e-02, 9.6929e-01]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 1st training example has a 99.91% probability of belonging to class 0 and a 0.09% probability of beloging to class 1."
      ],
      "metadata": {
        "id": "-zh6aWKiGYbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We can convert them into class labels using the argmax function\n",
        "predictions = torch.argmax(probas, dim=1)\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6aB0vKXGQq0",
        "outputId": "f0e108af-c91b-4638-ee1b-5c1c89ea3aaf"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 0, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions == Y_train"
      ],
      "metadata": {
        "id": "Lyv84Xl4HAnE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07ec154d-840c-47c3-dc37-eb3e1d99dd80"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([True, True, True, True, True])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementing a compute accuray function\n",
        "def compute_accuracy(model, dataloader):\n",
        "\n",
        "    model = model.eval()\n",
        "    correct = 0.0\n",
        "    total_examples = 0\n",
        "\n",
        "    for idx, (features, labels) in enumerate(dataloader):\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model(features)\n",
        "\n",
        "        predictions = torch.argmax(logits, dim=1)\n",
        "        compare = labels == predictions\n",
        "        correct += torch.sum(compare)\n",
        "        total_examples += len(compare)\n",
        "\n",
        "    return (correct / total_examples).item()\n",
        "\n",
        "compute_accuracy(model, train_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sT28RRQjunvE",
        "outputId": "df2fd11f-504c-4f34-fee7-b71c9425f004"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving and Loading Models\n"
      ],
      "metadata": {
        "id": "LyZp74m8xaNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "torch.save(model.state_dict(), \"model.pth\")"
      ],
      "metadata": {
        "id": "J4gtFc-fvvS1"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model’s state_dict is a Python dictionary object that maps each layer in the model to its trainable parameters (weights and biases)."
      ],
      "metadata": {
        "id": "ZTdt8HuLyCoK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model\n",
        "model = NeuralNetwork(2, 2) # needs to match the original model exactly\n",
        "model.load_state_dict(torch.load(\"model.pth\", weights_only=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WLAJUjWx7fi",
        "outputId": "fd1e8924-33c3-482c-ffa4-540731009d83"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HkbKqnNsyXWO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}